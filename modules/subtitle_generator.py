#!/usr/bin/env python3\n\"\"\"\nSubtitle Generator Module\nAutomatic speech-to-text untuk menghasilkan subtitle dari video\nMenggunakan OpenAI Whisper dan AI models untuk transcription berkualitas tinggi\n\"\"\"\n\nimport whisper\nimport torch\nimport numpy as np\nfrom pathlib import Path\nimport logging\nfrom typing import List, Dict, Tuple, Optional\nfrom dataclasses import dataclass\nimport json\nimport re\nfrom moviepy.editor import VideoFileClip\nimport librosa\nfrom datetime import timedelta\nimport srt\nimport webvtt\n\n# Import untuk subtitle formatting\ntry:\n    from googletrans import Translator\n    TRANSLATION_AVAILABLE = True\nexcept ImportError:\n    TRANSLATION_AVAILABLE = False\n    logging.warning(\"Google Translate not available. Translation features disabled.\")\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass TranscriptSegment:\n    \"\"\"Data class untuk transcript segment\"\"\"\n    start_time: float\n    end_time: float\n    text: str\n    confidence: float\n    speaker_id: Optional[int] = None\n    language: Optional[str] = None\n    word_timestamps: Optional[List[Dict]] = None\n    \n@dataclass\nclass SubtitleOptions:\n    \"\"\"Data class untuk subtitle formatting options\"\"\"\n    max_chars_per_line: int = 50\n    max_lines_per_subtitle: int = 2\n    min_duration: float = 1.0\n    max_duration: float = 7.0\n    font_size: int = 20\n    font_color: str = 'white'\n    background_color: str = 'black'\n    background_opacity: float = 0.7\n    position: str = 'bottom'  # 'top', 'bottom', 'center'\n    margin: int = 50\n    \nclass SubtitleGenerator:\n    def __init__(self, models_dir=None):\n        \"\"\"Initialize subtitle generator\"\"\"\n        self.models_dir = Path(models_dir) if models_dir else Path(__file__).parent.parent / \"models\"\n        self.models_dir.mkdir(exist_ok=True)\n        \n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        logger.info(f\"Using device: {self.device}\")\n        \n        # Whisper models: tiny, base, small, medium, large\n        self.whisper_model = None\n        self.model_size = 'base'  # Default model\n        \n        # Translation\n        self.translator = None\n        if TRANSLATION_AVAILABLE:\n            try:\n                self.translator = Translator()\n            except Exception as e:\n                logger.warning(f\"Could not initialize translator: {e}\")\n                \n        # Language detection\n        self.supported_languages = [\n            'id', 'en', 'zh', 'de', 'es', 'ru', 'ko', 'fr', 'ja', 'pt', 'tr', 'pl', \n            'ca', 'nl', 'ar', 'sv', 'it', 'hi', 'cs', 'he', 'fi', 'vi', 'uk', 'el'\n        ]\n        \n        self._load_models()\n        \n    def _load_models(self):\n        \"\"\"Load Whisper model\"\"\"\n        try:\n            logger.info(f\"Loading Whisper model ({self.model_size})...\")\n            self.whisper_model = whisper.load_model(self.model_size, device=self.device)\n            logger.info(\"Whisper model loaded successfully\")\n            \n        except Exception as e:\n            logger.error(f\"Error loading Whisper model: {e}\")\n            \n    def generate_subtitles(self, video_path, progress_callback=None, options=None):\n        \"\"\"\n        Main function untuk generate subtitles dari video\n        \n        Args:\n            video_path: Path ke video file\n            progress_callback: Function untuk progress updates\n            options: SubtitleOptions object\n            \n        Returns:\n            Dict dengan subtitle results\n        \"\"\"\n        try:\n            logger.info(f\"Starting subtitle generation: {video_path}\")\n            \n            if options is None:\n                options = SubtitleOptions()\n                \n            if progress_callback:\n                progress_callback(5, \"Mengekstrak audio dari video...\")\n                \n            # Extract audio dari video\n            audio_path = self._extract_audio(video_path)\n            if not audio_path:\n                return self._empty_result()\n                \n            if progress_callback:\n                progress_callback(15, \"Memuat audio untuk transcription...\")\n                \n            # Load audio untuk Whisper\n            audio_data = whisper.load_audio(audio_path)\n            \n            if progress_callback:\n                progress_callback(25, \"Menjalankan speech-to-text AI...\")\n                \n            # Transcribe dengan Whisper\n            transcript_result = self._transcribe_with_whisper(audio_data, progress_callback)\n            \n            if progress_callback:\n                progress_callback(70, \"Memproses dan memformat subtitle...\")\n                \n            # Process dan format transcript\n            processed_segments = self._process_transcript(transcript_result, options)\n            \n            if progress_callback:\n                progress_callback(85, \"Menghasilkan file subtitle...\")\n                \n            # Generate subtitle files\n            subtitle_files = self._generate_subtitle_files(processed_segments, video_path, options)\n            \n            # Cleanup temporary audio\n            try:\n                Path(audio_path).unlink()\n            except:\n                pass\n                \n            if progress_callback:\n                progress_callback(100, f\"Subtitle generation selesai - {len(processed_segments)} segment\")\n                \n            # Prepare results\n            results = {\n                'segments': processed_segments,\n                'subtitle_files': subtitle_files,\n                'statistics': self._generate_statistics(processed_segments),\n                'language': transcript_result.get('language', 'unknown'),\n                'total_duration': max(seg['end_time'] for seg in processed_segments) if processed_segments else 0\n            }\n            \n            logger.info(f\"Subtitle generation complete. Generated {len(processed_segments)} segments\")\n            return results\n            \n        except Exception as e:\n            logger.error(f\"Error generating subtitles: {e}\")\n            return self._empty_result()\n            \n    def _extract_audio(self, video_path):\n        \"\"\"Extract audio dari video untuk Whisper processing\"\"\"\n        try:\n            video = VideoFileClip(video_path)\n            audio = video.audio\n            \n            if not audio:\n                logger.warning(\"No audio track found in video\")\n                return None\n                \n            # Save audio dalam format yang Whisper bisa baca\n            audio_path = self.models_dir / \"temp_audio_whisper.wav\"\n            audio.write_audiofile(\n                str(audio_path), \n                verbose=False, \n                logger=None,\n                codec='pcm_s16le',  # Format yang Whisper prefer\n                ffmpeg_params=[\"-ar\", \"16000\"]  # 16kHz sample rate\n            )\n            \n            # Cleanup\n            audio.close()\n            video.close()\n            \n            return str(audio_path)\n            \n        except Exception as e:\n            logger.error(f\"Error extracting audio: {e}\")\n            return None\n            \n    def _transcribe_with_whisper(self, audio_data, progress_callback=None):\n        \"\"\"Transcribe audio menggunakan Whisper\"\"\"\n        try:\n            if not self.whisper_model:\n                self._load_models()\n                \n            if not self.whisper_model:\n                raise Exception(\"Whisper model not available\")\n                \n            # Whisper options\n            whisper_options = {\n                'task': 'transcribe',\n                'language': None,  # Auto-detect\n                'word_timestamps': True,  # Get word-level timestamps\n                'verbose': False\n            }\n            \n            # Progress tracking untuk Whisper\n            def whisper_progress_hook(progress_info):\n                if progress_callback:\n                    # Whisper progress adalah 25-70% dari total\n                    whisper_progress = 25 + (progress_info.get('progress', 0) * 45)\n                    progress_callback(whisper_progress, \"Memproses speech-to-text...\")\n                    \n            # Transcribe\n            result = self.whisper_model.transcribe(\n                audio_data,\n                **whisper_options\n            )\n            \n            # Post-process result\n            processed_result = {\n                'text': result['text'],\n                'language': result['language'],\n                'segments': []\n            }\n            \n            # Process segments\n            for segment in result['segments']:\n                processed_segment = {\n                    'start_time': segment['start'],\n                    'end_time': segment['end'],\n                    'text': segment['text'].strip(),\n                    'confidence': segment.get('avg_logprob', 0.0),\n                    'words': []\n                }\n                \n                # Add word-level timestamps jika available\n                if 'words' in segment:\n                    for word in segment['words']:\n                        word_info = {\n                            'word': word['word'],\n                            'start': word['start'],\n                            'end': word['end'],\n                            'probability': word.get('probability', 1.0)\n                        }\n                        processed_segment['words'].append(word_info)\n                        \n                processed_result['segments'].append(processed_segment)\n                \n            return processed_result\n            \n        except Exception as e:\n            logger.error(f\"Error in Whisper transcription: {e}\")\n            return {'text': '', 'language': 'unknown', 'segments': []}\n            \n    def _process_transcript(self, transcript_result, options):\n        \"\"\"Process dan format transcript untuk subtitle\"\"\"\n        try:\n            segments = transcript_result.get('segments', [])\n            if not segments:\n                return []\n                \n            processed_segments = []\n            \n            for segment in segments:\n                # Clean text\n                text = self._clean_text(segment['text'])\n                if not text or len(text.strip()) < 2:\n                    continue\n                    \n                # Split long text menjadi subtitle-friendly chunks\n                text_chunks = self._split_text_for_subtitle(text, options)\n                \n                # Create subtitle segments dari chunks\n                segment_duration = segment['end_time'] - segment['start_time']\n                \n                if len(text_chunks) == 1:\n                    # Single segment\n                    subtitle_segment = {\n                        'start_time': segment['start_time'],\n                        'end_time': segment['end_time'],\n                        'duration': segment_duration,\n                        'text': text_chunks[0],\n                        'confidence': segment.get('confidence', 0.0),\n                        'words': segment.get('words', [])\n                    }\n                    processed_segments.append(subtitle_segment)\n                else:\n                    # Multiple chunks - split time proportionally\n                    chunk_duration = segment_duration / len(text_chunks)\n                    \n                    for i, chunk in enumerate(text_chunks):\n                        start_time = segment['start_time'] + (i * chunk_duration)\n                        end_time = start_time + chunk_duration\n                        \n                        subtitle_segment = {\n                            'start_time': start_time,\n                            'end_time': end_time,\n                            'duration': chunk_duration,\n                            'text': chunk,\n                            'confidence': segment.get('confidence', 0.0),\n                            'words': []  # Word-level tidak tersedia untuk split segments\n                        }\n                        processed_segments.append(subtitle_segment)\n                        \n            # Post-process untuk timing optimization\n            processed_segments = self._optimize_subtitle_timing(processed_segments, options)\n            \n            return processed_segments\n            \n        except Exception as e:\n            logger.error(f\"Error processing transcript: {e}\")\n            return []\n            \n    def _clean_text(self, text):\n        \"\"\"Clean transcript text untuk subtitle\"\"\"\n        # Remove extra whitespace\n        text = re.sub(r'\\s+', ' ', text.strip())\n        \n        # Remove filler words yang umum\n        filler_words = ['um', 'uh', 'er', 'ah', 'hmm', 'eh']\n        words = text.split()\n        cleaned_words = [w for w in words if w.lower() not in filler_words]\n        text = ' '.join(cleaned_words)\n        \n        # Capitalize first letter\n        if text:\n            text = text[0].upper() + text[1:]\n            \n        # Add period jika tidak ada punctuation\n        if text and not text[-1] in '.!?':\n            text += '.'\n            \n        return text\n        \n    def _split_text_for_subtitle(self, text, options):\n        \"\"\"Split text untuk subtitle formatting\"\"\"\n        words = text.split()\n        if not words:\n            return []\n            \n        chunks = []\n        current_chunk = []\n        current_length = 0\n        \n        for word in words:\n            # Check jika adding word akan exceed limit\n            word_length = len(word) + (1 if current_chunk else 0)  # +1 for space\n            \n            if (current_length + word_length > options.max_chars_per_line and \n                current_chunk):\n                # Start new chunk\n                chunks.append(' '.join(current_chunk))\n                current_chunk = [word]\n                current_length = len(word)\n            else:\n                current_chunk.append(word)\n                current_length += word_length\n                \n        # Add final chunk\n        if current_chunk:\n            chunks.append(' '.join(current_chunk))\n            \n        return chunks\n        \n    def _optimize_subtitle_timing(self, segments, options):\n        \"\"\"Optimize subtitle timing untuk readability\"\"\"\n        if not segments:\n            return segments\n            \n        optimized = []\n        \n        for i, segment in enumerate(segments):\n            # Ensure minimum duration\n            if segment['duration'] < options.min_duration:\n                segment['end_time'] = segment['start_time'] + options.min_duration\n                segment['duration'] = options.min_duration\n                \n            # Ensure maximum duration\n            if segment['duration'] > options.max_duration:\n                segment['end_time'] = segment['start_time'] + options.max_duration\n                segment['duration'] = options.max_duration\n                \n            # Avoid overlap dengan next segment\n            if i < len(segments) - 1:\n                next_segment = segments[i + 1]\n                if segment['end_time'] > next_segment['start_time']:\n                    # Add small gap\n                    gap = 0.1  # 100ms gap\n                    segment['end_time'] = next_segment['start_time'] - gap\n                    segment['duration'] = segment['end_time'] - segment['start_time']\n                    \n            optimized.append(segment)\n            \n        return optimized\n        \n    def _generate_subtitle_files(self, segments, video_path, options):\n        \"\"\"Generate subtitle files dalam berbagai format\"\"\"\n        try:\n            video_name = Path(video_path).stem\n            output_dir = Path(video_path).parent\n            \n            subtitle_files = {}\n            \n            # Generate SRT format\n            srt_path = output_dir / f\"{video_name}_subtitles.srt\"\n            self._generate_srt_file(segments, srt_path)\n            subtitle_files['srt'] = str(srt_path)\n            \n            # Generate VTT format\n            vtt_path = output_dir / f\"{video_name}_subtitles.vtt\"\n            self._generate_vtt_file(segments, vtt_path, options)\n            subtitle_files['vtt'] = str(vtt_path)\n            \n            # Generate ASS format dengan styling\n            ass_path = output_dir / f\"{video_name}_subtitles.ass\"\n            self._generate_ass_file(segments, ass_path, options)\n            subtitle_files['ass'] = str(ass_path)\n            \n            return subtitle_files\n            \n        except Exception as e:\n            logger.error(f\"Error generating subtitle files: {e}\")\n            return {}\n            \n    def _generate_srt_file(self, segments, output_path):\n        \"\"\"Generate SRT subtitle file\"\"\"\n        try:\n            srt_subtitles = []\n            \n            for i, segment in enumerate(segments, 1):\n                start_time = timedelta(seconds=segment['start_time'])\n                end_time = timedelta(seconds=segment['end_time'])\n                \n                subtitle = srt.Subtitle(\n                    index=i,\n                    start=start_time,\n                    end=end_time,\n                    content=segment['text']\n                )\n                \n                srt_subtitles.append(subtitle)\n                \n            # Write SRT file\n            with open(output_path, 'w', encoding='utf-8') as f:\n                f.write(srt.compose(srt_subtitles))\n                \n            logger.info(f\"SRT file generated: {output_path}\")\n            \n        except Exception as e:\n            logger.error(f\"Error generating SRT file: {e}\")\n            \n    def _generate_vtt_file(self, segments, output_path, options):\n        \"\"\"Generate WebVTT subtitle file\"\"\"\n        try:\n            vtt = webvtt.WebVTT()\n            \n            for segment in segments:\n                start_time = self._seconds_to_vtt_time(segment['start_time'])\n                end_time = self._seconds_to_vtt_time(segment['end_time'])\n                \n                caption = webvtt.Caption(\n                    start=start_time,\n                    end=end_time,\n                    text=segment['text']\n                )\n                \n                vtt.captions.append(caption)\n                \n            # Save VTT file\n            vtt.save(str(output_path))\n            logger.info(f\"VTT file generated: {output_path}\")\n            \n        except Exception as e:\n            logger.error(f\"Error generating VTT file: {e}\")\n            \n    def _generate_ass_file(self, segments, output_path, options):\n        \"\"\"Generate ASS subtitle file dengan advanced styling\"\"\"\n        try:\n            # ASS header\n            ass_content = \"\"\"[Script Info]\nTitle: Auto-generated Subtitles\nScriptType: v4.00+\n\n[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\nStyle: Default,Arial,{fontsize},&H00FFFFFF,&H000000FF,&H00000000,&H80000000,0,0,0,0,100,100,0,0,1,2,0,2,{margin},{margin},{margin},1\n\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n\"\"\".format(\n                fontsize=options.font_size,\n                margin=options.margin\n            )\n            \n            # Add dialogue lines\n            for segment in segments:\n                start_time = self._seconds_to_ass_time(segment['start_time'])\n                end_time = self._seconds_to_ass_time(segment['end_time'])\n                \n                dialogue_line = f\"Dialogue: 0,{start_time},{end_time},Default,,0,0,0,,{segment['text']}\\n\"\n                ass_content += dialogue_line\n                \n            # Write ASS file\n            with open(output_path, 'w', encoding='utf-8') as f:\n                f.write(ass_content)\n                \n            logger.info(f\"ASS file generated: {output_path}\")\n            \n        except Exception as e:\n            logger.error(f\"Error generating ASS file: {e}\")\n            \n    def _seconds_to_vtt_time(self, seconds):\n        \"\"\"Convert seconds ke VTT time format\"\"\"\n        hours = int(seconds // 3600)\n        minutes = int((seconds % 3600) // 60)\n        secs = seconds % 60\n        return f\"{hours:02d}:{minutes:02d}:{secs:06.3f}\"\n        \n    def _seconds_to_ass_time(self, seconds):\n        \"\"\"Convert seconds ke ASS time format\"\"\"\n        hours = int(seconds // 3600)\n        minutes = int((seconds % 3600) // 60)\n        secs = seconds % 60\n        centiseconds = int((secs - int(secs)) * 100)\n        return f\"{hours:01d}:{minutes:02d}:{int(secs):02d}.{centiseconds:02d}\"\n        \n    def _generate_statistics(self, segments):\n        \"\"\"Generate statistics tentang subtitle\"\"\"\n        if not segments:\n            return {}\n            \n        total_duration = sum(seg['duration'] for seg in segments)\n        total_text = ' '.join(seg['text'] for seg in segments)\n        \n        statistics = {\n            'total_segments': len(segments),\n            'total_duration': total_duration,\n            'total_characters': len(total_text),\n            'total_words': len(total_text.split()),\n            'average_segment_duration': total_duration / len(segments),\n            'average_confidence': np.mean([seg['confidence'] for seg in segments]),\n            'reading_speed_wpm': len(total_text.split()) / (total_duration / 60) if total_duration > 0 else 0\n        }\n        \n        return statistics\n        \n    def _empty_result(self):\n        \"\"\"Return empty result structure\"\"\"\n        return {\n            'segments': [],\n            'subtitle_files': {},\n            'statistics': {},\n            'language': 'unknown',\n            'total_duration': 0\n        }\n        \n    def translate_subtitles(self, segments, target_language='id'):\n        \"\"\"Translate subtitles ke bahasa lain\"\"\"\n        try:\n            if not self.translator or not TRANSLATION_AVAILABLE:\n                logger.warning(\"Translation not available\")\n                return segments\n                \n            translated_segments = []\n            \n            for segment in segments:\n                try:\n                    # Translate text\n                    translated = self.translator.translate(\n                        segment['text'], \n                        dest=target_language\n                    )\n                    \n                    # Create new segment dengan translated text\n                    translated_segment = segment.copy()\n                    translated_segment['text'] = translated.text\n                    translated_segment['original_text'] = segment['text']\n                    translated_segment['translated_from'] = translated.src\n                    translated_segment['translated_to'] = target_language\n                    \n                    translated_segments.append(translated_segment)\n                    \n                except Exception as e:\n                    logger.warning(f\"Could not translate segment: {e}\")\n                    # Keep original jika translation fails\n                    translated_segments.append(segment)\n                    \n            return translated_segments\n            \n        except Exception as e:\n            logger.error(f\"Error in translation: {e}\")\n            return segments\n            \n    def save_subtitle_results(self, results, output_path):\n        \"\"\"Save subtitle results ke JSON file\"\"\"\n        try:\n            with open(output_path, 'w', encoding='utf-8') as f:\n                json.dump(results, f, indent=2, ensure_ascii=False)\n                \n            logger.info(f\"Subtitle results saved to {output_path}\")\n            \n        except Exception as e:\n            logger.error(f\"Error saving subtitle results: {e}\")\n\n# Test function\nif __name__ == \"__main__\":\n    # Test subtitle generator\n    generator = SubtitleGenerator()\n    \n    def test_progress(progress, message):\n        print(f\"Progress: {progress}% - {message}\")\n    \n    print(\"Subtitle Generator module loaded successfully\")\n    print(f\"Whisper model: {generator.model_size}\")\n    print(f\"Translation available: {TRANSLATION_AVAILABLE}\")\n    \n    # Test dengan sample video (uncomment untuk testing)\n    # options = SubtitleOptions(\n    #     max_chars_per_line=40,\n    #     font_size=18,\n    #     font_color='white'\n    # )\n    # \n    # video_path = \"test_video.mp4\"\n    # results = generator.generate_subtitles(video_path, test_progress, options)\n    # \n    # print(f\"\\nGenerated {len(results['segments'])} subtitle segments\")\n    # print(f\"Language detected: {results['language']}\")\n    # print(f\"Subtitle files: {list(results['subtitle_files'].keys())}\")